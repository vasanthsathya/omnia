# Copyright 2024 Dell Inc. or its subsidiaries. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---

# Usage: validate_telemetry_config.yml
omnia_metadata_file: "/opt/omnia/.data/oim_metadata.yml"
telemetry_config_file: "{{ input_project_dir }}/telemetry_config.yml"
fail_msg_telemetry_config_file: "telemetry_config.yml file doesn't exist."
pause_time_15: 15
bmc_group_data_filename: "/opt/omnia/telemetry/bmc_group_data.csv"
warning_telemetry_support_false: |
  "[WARNING] idrac_telemetry_support and visualization_support are false in telemetry_config.yml.
  Omnia does not deploy telemetry feature if none of the support category is true."
telemetry_config_syntax_fail_msg: "Failed. Syntax errors present in telemetry_config.yml. Fix errors and re-run playbook again."
warning_idrac_telemetry_support_false: |
  "[WARNING] idrac_telemetry_support is set to false in telemetry_config.yml. This means iDRAC telemetry will not be activated.
  To use telemetry, set idrac_telemetry_support to true in telemetry_config.yml.
  Note that Omnia does not support disabling telemetry if containers are already running.
  To remove telemetry containers, use the utils/oim_cleanup.yml playbook."
warning_idrac_telemetry_support_true: |
  "[WARNING] idrac_telemetry_support is set to true in telemetry_config.yml.
  iDRAC telemetry will be activated for all BMC IPs listed in {{ bmc_group_data_filename }}.
  Confirm that all BMC IPs are reachable from the OIM and respective service cluster nodes for telemetry to function properly.
  Make sure that Redfish is enabled and the iDRAC has a datacenter license.
  Also, ensure that the firmware version is greater than 4 for iDRAC9 or greater than 1 for iDRAC10."
warning_federated_telemetry_support: "Failed: Federated iDRAC Telemetry Collection is not supported yet and will be available in future releases."

# # Usage: include_provision_config.yml
# provision_config_file: "{{ input_project_dir }}/provision_config.yml"
# fail_msg_provision_config_file: "provision_config.yml file doesn't exist."
# fail_timezone_msg: "Failed. Incorrect timezone provided. Please check the file timezone.txt in discovery/roles/discovery_validations/common/files/ folder."

# # Usage: validate_k8s_prometheus_prometheus_gaudi.yml
# k8s_prom_gaudi_inventory_fail_msg: "Inventory comprising kube_control_plane, kube_node and etcd groups should be passed  \
# when k8s_prometheus_support or prometheus_gaudi_support is true in telemetry_config.yml."
# prometheus_scrape_interval_fail_msg: "Failed. prometheus_scrape_interval accepts integer values greater than 0"

# Usage: validate_image_tars.yml
# noqa: yaml[line-length]
omnia_images_tar_missing_msg: |
  Following images tarball(s) are missing: {{ missing_tars }}.
  To ensure these tar files are present at {{ omnia_images_dir_path }}, execute the utility below:
    `ansible-playbook utils/save_container_images.yml -e 'visualization_support=true idrac_telemetry_support=true k8s_support=true'`
  After saving the images, re-run the telemetry playbook.

# Usage: read_software_config.yml
software_config_file: "{{ input_project_dir }}/software_config.json"
# local_repo_sn_missing_msg: |
#   [ERROR] It seems local_repo not executed with service_node entry in software_config.yml.
#   Kindly execute local_repo.yml with `service_node` entry in softwares list in software_config.yml
#   and then execute telemetry.yml.
local_repo_service_missing_msg: |
  [ERROR] It seems local_repo not executed with service_k8s/service_node entry in software_config.yml.
  Kindly execute local_repo.yml with `service_k8s` or `service_node` entry in softwares list in software_config.yml
  and then execute telemetry.yml.
local_repo_access_path: "/opt/omnia/provision/local_repo_access.yml"
# sn_packages_file: "{{ input_project_dir }}/config/{{ software_config.cluster_os_type }}/{{ software_config.cluster_os_version }}/service_node.json"
k8s_packages_file: "{{ input_project_dir }}/config/{{ software_config.cluster_os_type }}/{{ software_config.cluster_os_version }}/service_k8s.json"
downloaded_sw_log_csv: "/opt/omnia/log/local_repo/software.csv"
software_config_syntax_fail_msg: "Failed. Syntax errors present in software_config.json. Fix errors and re-run playbook again."

# # Usage: validate_prometheus_gaudi.yaml
# fail_msg_k8s_prometheus_support_false: "Failed. k8s_prometheus_support must be true when prometheus_gaudi_support is true in telemetry_config.yml."
# fail_msg_prometheus_gaudi_support: "Failed. prometheus_gaudi_support is only available for cluster_os_type: ubuntu and cluster_os_version: 22.04 , 24.04. \
# Please update prometheus_gaudi_support to false in telemetry_config.yml."

# # Usage: validate_k8s_setup.yml
# k8s_error_message: "No such file or directory"
# k8s_cluster_fail_msg: "Failed. k8s cluster setup not found. Hence k8s prometheus or prometheus gaudi will not be deployed. \
# Please run scheduler/scheduler.yml to setup k8s cluster"

# # Usage: validate_site_config.yml
# site_config_file: "{{ input_project_dir }}/site_config.yml"
# invalid_proxy_failure_msg: "Failed. Both http_proxy and https_proxy should be set for proxy variable provided in site_config.yml"
# # proxy_env_fail_msg: "Failed. The values for http_proxy {{ proxy[0].http_proxy }} and https_proxy {{ proxy[0].https_proxy }} in the
# # proxy variable of the site_config.yml should be set as environment variables http_proxy and https_proxy in the Omnia Infrastructure Manager.
# # The no_proxy environment variable should include the Omnia Infrastructure Manager hostname and the admin network IP address."
# update_repos_fail_msg: "Failed to update repos. Verify proxy configuration in Omnia Infrastructure Manager for acccessing internet."
# oim_os_redhat: "redhat"
# oim_os_rocky: "rocky"
# oim_os_ubuntu: "ubuntu"
# repo_retries: 5
# repo_delay: 10
# dnf_conf_path: "/etc/dnf/dnf.conf"

# Usage: validate_idrac_inventory.yml
bmc_group_data_file_not_found_msg: "Failed. The BMC data file: {{ bmc_group_data_filename }} does not exist.
 Please execute discovery_provision.yml to Generate BMC data file."
bmc_group_data_headers: "BMC_IP,GROUP_NAME,PARENT"
bmc_group_data_invalid_msg: "Failed. Invalid BMC data file: {{ bmc_group_data_filename }}.
 Please execute discovery_provision.yml to Generate BMC data file."
bmc_group_data_invalid_ip_msg: "Failed. Invalid BMC IP present in the file: {{ bmc_group_data_filename }}. BMC IP"
bmc_group_data_empty_msg: "Failed. No BMC entries found in BMC group data file {{ bmc_group_data_filename }}."

# Usage: validate_telemetry_container.yml
telemetry_container_status_msg: "Telemetry container Status: {{ telemetry_container_status.containers[0].State.Status }}"
telemetry_container_fail_msg: "Telemetry container {{ telemetry_container }} is not running.
 Current Status: {{ telemetry_container_status.containers[0].State.Status }}"
prepare_oim_telemetry_not_executed_msg: "Telemetry container {{ telemetry_container }} not found.
 Please execute prepare_oim.yml to deploy all required containers."

# Usage: add_host_goups.yml
service_node_metadata_path: "/opt/omnia/.data/service_node_metadata.yml"
cluster_layout_path: "/opt/omnia/omnia_inventory/cluster_layout"
invalid_parent_tags_message: |
  [ERROR] Invalid parent tags : {{ host_inventory.invalid_parent_tags }}.
  These parent tags found in `{{ bmc_group_data_filename }}` are not of service nodes.
  If your are adding a bmc entry in the csv file, please ensure that the parent tag is service tag of service node.
  If service nodes are not provisioned or compute node provisioning not initiated,
  please run discovery_provision.yml to provision service nodes and compute nodes from service nodes.
  And then run `telemetry.yml` playbook again.

# Usage: include_high_availability_config.yml
high_availability_config_path: "{{ input_project_dir }}/high_availability_config.yml"
fail_msg_high_availability_config_file: "high_availability_config.yml file doesn't exist."
high_availability_config_syntax_fail_msg: "Failed. Syntax errors present in high_availability_config.yml. Fix errors and re-run playbook again."

# Usage: validate_service_node_status.yml
service_node_not_defined: |
  service_node is not defined in roles_config.yml.
  Federated way of idrac telemetry collection is supported only for hierarchical cluster.
  Please disable federated_idrac_telemetry_collection in telemetry_config.yml and execute telemetry.yml.
service_node_not_booted: |
  The following service nodes with these service tags are currently not booted: {{ validation_result.service_nodes_not_booted | join(', ') }}.
  Please wait for the nodes to boot or re-provision the nodes in case of failure.

# Usage: include_network_spec.yml
network_spec_path: "{{ input_project_dir }}/network_spec.yml"
fail_msg_network_spec_file: "network_spec.yml file doesn't exist."
network_spec_syntax_fail_msg: "Failed. Syntax errors present in network_spec.yml. Fix errors and re-run playbook again."
