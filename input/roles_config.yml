# Copyright 2025 Dell Inc. or its subsidiaries. All Rights Reserved.
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
---

# ***********************************************************************
# DO NOT REMOVE OR COMMENT OUT ANY LINES IN THIS FILE.
# SIMPLY APPEND THE REQUIRD VALUES AGAINST THE PARAMETER OF YOUR CHOICE.
# ***********************************************************************

#*************************************************************************************************************************
# Groups
#*************************************************************************************************************************
# roles_config.yml file takes input parameters for the composable roles and groups.
# This file contains Roles and Groups used by the omnia for cluster formation.
# Groups: - Groups will contain the list of groups defined by the user. User must define atleast one group.
#   grpN:                 - <Mandatory> "grpN" -  User defined name of the group. Range for N is 0-99
#     cluster_name:       - <Conditional Mandatory> Name of the cluster to which the group belongs. This input is case-sensitive. This will remain empty for groups which are not associated with any kubernetes roles.
#     location_id:        - <Mandatory> SU-<n>.RACK-<n> Scalable unit and rack number range is 0-99. This input is case-sensitive. Please use uppercase letters only.
#     resource_mgr_id:    - <Conditional Mandatory> list of service tag of active head node(s).
#                         - Set the value only for group of nodes belonging to kube_node and slurm_node roles,
#                         - And empty for other roles.
#     parent:             - <Conditional Mandatory> list of service tag of associated active service node(s).
#                         - This field will be empty for group of nodes which is associated with ‘login’, ‘compiler_node’, ‘service_node’,
#                         - ‘auth_server’, ‘service_kube_control_plane’, 'service_etcd', ‘kube_control_plane’, ‘etcd’, 'slurm_control_node’.
#                         - If ‘service’ role is not defined, then value will be empty for worker and default role.
#     bmc_details:        - <Conditional Mandatory> BMC IP static range in the format 10.5.0.1-10.5.0.200
#        static_range:    - <Mandatory> This field mandatory in case of BMC discovery of subset of nodes
#     switch_details      - <Conditional Mandatory> Switch details of the Rack
#        ip:              - <Mandatory> IP address of the switch
#        ports:           - <Mandatory> ports of the switch
#     architecture        - <Mandatory> architecture of the nodes - x86 or ARM
#

Groups:
  grp0:
    location_id: SU-1.RACK-1
    cluster_name: ""
    resource_mgr_id: ""
    parent: ""
    bmc_details:
      static_range: ""
    switch_details:
      ip: ""
      ports: ""
    architecture: "x86"

  # grp1:
  #   location_id: SU-1.RACK-2
  #   cluster_name: ""
  #   resource_mgr_id: ""
  #   parent: ""
  #   bmc_details:
  #     static_range: ""
  #   switch_details:
  #     ip: ""
  #     ports: ""
  #   architecture: "x86"

#************************************************************************************************************************
#  Roles
#************************************************************************************************************************
# Atleast one role is mandatory, and User is not allowed to change the name of the roles.
# Maximum number of roles supported are 100.
# Note: Nested roles and groups are not supported.
# The roles are case sensitive
#   - name:                           - <Mandatory> Name of the role, can be any of the following Omnia defined roles.
#     groups:                         - <Mandatory> list of groups defined by the user
#

# This table lists the roles and the layers they belong to in the cluster.

# +---------------------------+------------------+     +-------------------+----------------+
# | Role Name                  | Layer           |     | Role Name         | Layer          |
# +---------------------------+------------------+     +-------------------+----------------+
# | oim_ha_node                | management      |     | default           | compute        |
# | service_kube_control_plane | management      |     | kube_node         | compute        | 
# | service_etcd               | management      |     | slurm_node        | compute        |
# | service_kube_node          | management      |     |                   |                |
# | service_node (future use)  | management      |     |                   |                |
# | login                      | management      |     |                   |                |
# | auth_server                | management      |     |                   |                |
# | compiler_node              | management      |     |                   |                |
# | kube_control_plane         | management      |     |                   |                |
# | etcd                       | management      |     |                   |                |
# | slurm_control_node         | management      |     |                   |                |
# +---------------------------+------------------+     +-------------------+----------------+

# Default Role:
# -------------
#
# This role is provided to cover the default role of the cluster.
#
# The default role is assigned to nodes which do not fit into any specific roles.
# If user wants to just provision the group of nodes without associating with any role,
# then the default role can be used.
#
# This role belongs to the compute layer.
#
Roles:
  - name: "default"
    groups:
      - grp0


# OIM HA Node Role:
# -------------
#
# This role is used to configure passive OIM nodes.
#
# The nodes included in this role will have the necessary tools and
# configurations needed to be passive OIM nodes.
#
# The nodes in this role can be used in case of OIM failure.
#
  # - name: "oim_ha_node"
  #   groups:
  #     - grp0

#
# Service k8s head Role: Service Cluster Kubernetes master node for groups to add into service_kube_control_plane role can be provided in this role
# ----------------------------------------------------------------------------------------------------
# 
# This role is used to configure kubernetes master on service cluster.
#
# This role should not have same group as of K8s head Role.
#
# The nodes included in this role will have the necessary tools and
# configurations to configure kubernetes master on service cluster.
#
# The nodes in this role can be used to run kubernetes master on service cluster.
#
# Service k8s head Role: Service Cluster Kubernetes master node for groups to add into service_kube_control_plane role can be provided in this role
  # - name: "service_kube_control_plane"
  #   groups:
  #     - grp0
  #     - grp1

#
# Service etcd Role: Service Cluster Kubernetes etcd node groups to add into service cluster k8s role can be provided in this role
# ------------------------------------------------------------------------------------
#
# This role is used to configure the nodes for Kubernetes etcd on service cluster.
#
# This role should not have same group as of K8s etcd Role.
#
# The nodes included in this role will have the necessary tools and
# configurations to configure Kubernetes etcd on service cluster.
#
# The nodes in this role can be used to run Kubernetes etcd on service cluster.
#
# Service etcd Role: Service Cluster Kubernetes etcd node groups to add into service cluster k8s role can be provided in this role
  # - name: "service_etcd"
  #   groups:
  #     - grp0
  #     - grp1

#
# Service k8s Worker Role: Service Cluster Kubernetes worker node groups to add into service cluster k8s role can be provided in this role
# ------------------------------------------------------------------------------------
#
# This role is used to configure the nodes for Kubernetes worker on service cluster.
#
# This role should not have same group as of K8s Worker node.
#
# The nodes included in this role will have the necessary tools and
# configurations to configure Kubernetes worker on service cluster.
#
# The nodes in this role can be used to run Kubernetes worker on service cluster.
#
# Service k8s Worker Role: Service Cluster Kubernetes worker node groups to add into service cluster k8s role can be provided in this role
  # - name: "service_kube_node"
  #   groups:
  #     - grp0
  #     - grp1

# ----------------------------------------Not Supported ( Future Use )---------------------------------
# Service Node Role: Service node groups to add into service_node role can be provided in this role
# ------------------------------------------------------------------------------------
#
# This role is used to configure the nodes for service group. It belongs to the management layer.
#
# The nodes included in this role will have the necessary tools and
# configurations to configure service node.
#
# The nodes in this role can be used to run service.
#
  # - name: "service_node"
  #   groups:
  #     - grp0
  #     - grp1

#
# K8s head Role: Kubernetes master node groups to add into kube_control_plane role can be provided in this role
# ---------------------------------------------------------------------------------------
#
# This role is used to configure the nodes for Kubernetes master. It belongs to the management layer.
#
# The nodes included in this role will have the necessary tools and
# configurations to run Kubernetes master.
#
# The nodes in this role can be used to run Kubernetes master.
#
# K8s head Role: Kubernetes master groups to add into etcd role can be provided in this role
  # - name: "kube_control_plane"
  #   groups:
  #     - grp0
  #     - grp1

#
# K8s etcd Role: Kubernetes etcd node groups to add into k8s role can be provided in this role
# ---------------------------------------------------------------------------------------------
#
# This role is used to configure the nodes for Kubernetes etcd. It belongs to the management layer.
#
# The nodes included in this role will have the necessary tools and
# configurations to run Kubernetes etcd.
#
# The nodes in this role can be used to run Kubernetes etcd.
#
# K8s etcd Role: Kubernetes etcd groups to add into k8s etcd role can be provided in this role
  # - name: "etcd"
  #   groups:
  #     - grp0
  #     - grp1

#
# K8s Worker Role: Kubernetes worker node groups to add into k8s role can be provided in this role
# -----------------------------------------------------------------------------------------------
#
# This role is used to configure the nodes for Kubernetes worker. It belongs to the compute layer.
#
# The nodes included in this role will have the necessary tools and
# configurations to run Kubernetes worker.
#
# The nodes in this role can be used to run Kubernetes worker.
#
# K8s Worker Role: Kubernetes worker groups to add into k8s worker role can be provided in this role
  # - name: "kube_node"
  #   groups:
  #     - grp0
  #     - grp1

#
# Slurm Head Role: Slurm head node groups to add into Slurm role can be provided in this role
# ------------------------------------------------------------------------------------------
#
# This role is used to configure the nodes for Slurm head. It belongs to the management layer.
#
# The nodes included in this role will have the necessary tools and
# configurations to run Slurm head.
#
# The nodes in this role can be used to run Slurm head.
# This role belongs to the compute layer.
#
# Slurm Head Role: Slurm head groups to add into slurm_control_node role can be provided in this role
  # - name: "slurm_control_node"
  #   groups:
  #     - grp0
  #     - grp1

#
# Slurm Worker Role: Slurm worker node groups to add into Slurm role can be provided in this role
# ------------------------------------------------------------------------------------------------
#
# This role is used to configure the nodes for Slurm worker. It belongs to the compute layer.
#
# The nodes included in this role will have the necessary tools and
# configurations to run Slurm worker.
#
# The nodes in this role can be used to run Slurm worker.
#
# Slurm Worker Role: Slurm worker groups to add into Slurm role can be provided in this role
  # - name: "slurm_node"
  #   groups:
  #     - grp0
  #     - grp1

#
# Login Role:
# -----------
#
# This role is used to configure the nodes for user logins. It belongs to the management layer.
#
# The nodes included in this role will have the necessary tools and configurations
# to support user login activities.
#
# The user is not allowed to change the name of this role.
#
  # - name: "login"
  #   groups:
  #     - grp0
  #     - grp1

#
# Auth Server Role:
# -----------------
#
# This role is used to configure the nodes for authentication. It belongs to the management layer.
#
# The nodes included in this role will have the necessary tools and configurations
# to support authentication activities.
#
# The user is not allowed to change the name of this role.
#
  # - name: "auth_server"
  #   groups:
  #     - grp0
  #     - grp1

#
# Compiler Node Role:
# --------------
#
# This role is used to configure the nodes for compilation. It belongs to the management layer.
#
# The nodes included in this role will have the necessary tools and
# configurations to perform compilation.
#
# The nodes in this role can be used to compile the code.
#
# Compiler Node Role: Compiler groups to add into compiler_node role can be provided in this role
  # - name: "compiler_node"
  #   groups:
  #     - grp0
  #     - grp1
